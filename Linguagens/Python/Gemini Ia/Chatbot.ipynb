{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importando e configurando a SDK**\n",
        "### API key pode ser gerada no Google AI Studio"
      ],
      "metadata": {
        "id": "ORr463IjqBGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n",
        "\n",
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY='AIzaSyCP--wodu3p8AW2mNpcYSbTdItokbUuHIk'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "w4avcWbWqbI8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lista dos modelos**\n",
        "### usando loop for"
      ],
      "metadata": {
        "id": "019LuXLorjyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in genai.list_models():\n",
        "  if \"generateContent\" in i.supported_generation_methods:\n",
        "    print(i.name)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "kgJM5hhIronl",
        "outputId": "5d3119ea-54e4-4bcc-954d-bd53b8cd40ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criar os parametros que serão usados\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "h67O48AGvsIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configGeracao = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "Y8opUpFgv4Fu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parametros de segurança**"
      ],
      "metadata": {
        "id": "cRFFSez6xG_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configSec = {\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "}"
      ],
      "metadata": {
        "id": "zs6L7qxbxO3W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inicializar o modelo"
      ],
      "metadata": {
        "id": "avUvUvL_x-N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\", safety_settings=configSec, generation_config=configGeracao)\n"
      ],
      "metadata": {
        "id": "-s5JlQ5VyA2C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geração"
      ],
      "metadata": {
        "id": "rJysUst7zGhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#resposta_input = model.generate_content(\"Olá meu nome é python\")\n",
        "#print(resposta_input.text)\n",
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "QK-3nqtRzLIS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Esperando prompt\")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  resposta = chat.send_message(prompt)\n",
        "  print(f\"Resposta: {resposta.text} \\n\")\n",
        "  prompt = input(\"Esperando prompt: \")"
      ],
      "metadata": {
        "id": "Ups4EV1d13YL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "44e93a47-c1c8-4b5e-be2a-9d001774a27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esperando promptOlá chat gpt\n",
            "Resposta: Não sou o chat gpt. Sou Gemini, um modelo de linguagem de IA multimodal desenvolvido pelo Google. \n",
            "\n",
            "Esperando prompt: a desculpe google assistente\n",
            "Resposta: Não sou o Google Assistente. Sou Gemini, um modelo de linguagem de IA multimodal desenvolvido pelo Google. \n",
            "\n",
            "Esperando prompt: a desculpe genesis\n",
            "Resposta: Não sou Gênesis. Sou Gemini, um modelo de linguagem de IA multimodal desenvolvido pelo Google. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x6AVgc3wwl3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b7fUUQ5Qv3DO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kjuEkDZFp7Xm"
      }
    }
  ]
}